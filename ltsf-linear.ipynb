{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b83e78c-9c15-4742-a4f1-03e1447032bd",
   "metadata": {},
   "source": [
    "# LTSF-Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f46fae9-032a-4a0c-9f2c-c7f4bee81a83",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "In the following cell, we import the required libraries necessary for training and testing our LTSF-Linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bca25b8-2631-481a-aeb0-ae3e532eebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad9320c-065d-4366-b580-1481e24ccd35",
   "metadata": {},
   "source": [
    "## Model Definitions\n",
    "\n",
    "In the following cells, we create the modules necessary for our long-term time series forecasting project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a039a4a-6d81-44ad-b5ca-5a84548a4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLTSF(nn.Module):\n",
    "    def __init__(self, sequence_length, prediction_length, in_channels=2):\n",
    "        super(LinearLTSF, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.prediction_length = prediction_length\n",
    "        self.linears = nn.ModuleList([\n",
    "            nn.Linear(sequence_length, prediction_length)\n",
    "            for _ in range(in_channels)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.tensor([], dtype=x.dtype, device=x.device)\n",
    "        for channel, linear in enumerate(self.linears):\n",
    "            channel_out = linear(x[:, :, channel]).unsqueeze(-1)\n",
    "            out = torch.cat([out, channel_out], dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda9af6d-35c2-4620-ab22-581fec2ed6c2",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We create the ApplianceEnergyUsageDataset to forecast energy usage for lights and appliances by our Linear modules we defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "724794f6-6ecf-47e0-a1fd-6ca9e01cd4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplianceEnergyUsageDataset(Dataset):\n",
    "    def __init__(self, energy_data, sequence_length, prediction_length):\n",
    "        super().__init__()\n",
    "        self.energy_data = energy_data\n",
    "        self.sequence_length = sequence_length\n",
    "        self.prediction_length = prediction_length        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sequence_begin = index\n",
    "        sequence_end = sequence_begin + self.sequence_length\n",
    "        x = self.energy_data[sequence_begin:sequence_end]\n",
    "        prediction_begin = sequence_end\n",
    "        prediction_end = prediction_begin + self.prediction_length\n",
    "        y = self.energy_data[prediction_begin:prediction_end]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.energy_data) - self.sequence_length - self.prediction_length + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba79605d-19a9-43ee-8222-ea4a00f17888",
   "metadata": {},
   "source": [
    "### Dataset Helpers\n",
    "\n",
    "We create the utility functions necessary for retrieving separate training and test datasets for use by our Linear models. Additionally, we apply the normalization to the test data by the mean and variance of the training data, as suggested in the literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22a9117-e462-42f7-8c2e-a14b1964759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_data_file = '../../datasets/appliances_energy_prediction/energydata_complete.csv'\n",
    "energy_data = pd.read_csv(energy_data_file, usecols=[1, 2])\n",
    "training_samples = int(len(energy_data) * 0.8)\n",
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(energy_data.iloc[:training_samples].values)\n",
    "\n",
    "def get_train_dataset(sequence_length, prediction_length):\n",
    "    dataset = ApplianceEnergyUsageDataset(train_data, \n",
    "                                          sequence_length, \n",
    "                                          prediction_length)\n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(sequence_length, prediction_length):\n",
    "    test_data = scaler.transform(energy_data.iloc[\n",
    "        training_samples - sequence_length:].values)\n",
    "    dataset = ApplianceEnergyUsageDataset(test_data,\n",
    "                                          sequence_length,\n",
    "                                          prediction_length)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d960182f-d649-4ade-a5dc-c7681ace5c1c",
   "metadata": {},
   "source": [
    "## Model Training/Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd42e9-58ec-4a44-bdd2-7498663f1a00",
   "metadata": {},
   "source": [
    "### Train/Evaluate Helper Functions\n",
    "\n",
    "Additional utility functions for training and evaluating our Linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee49d5f6-9635-4a6d-94b0-13ddf95287b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    for X, y in dataloader:\n",
    "        X, y = [_.to(torch.float32).to(device) for _ in (X, y,)]\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "def test(dataloader, model, criterion):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = [_.to(torch.float32).to(device) for _ in (X, y,)]\n",
    "            pred = model(X)\n",
    "            test_loss += criterion(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70c620c-39b1-4ff0-a6ae-9e6f2bf85362",
   "metadata": {},
   "source": [
    "In the following cell, we obtain loss statistics on the test dataset for different values of the look-back window (24 or 720) and different forecasting lengths for the prediction horizon (48, 72, 96, 120, 144, 168, 192, 336, 504, 672, 720)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7907a4-1d1e-4808-a1ef-d91d2e4b2c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prediction Length': [24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 720, 720, 720, 720, 720, 720, 720, 720, 720, 720, 720], 'Sequence Length': [48, 72, 96, 120, 144, 168, 192, 336, 504, 672, 720, 48, 72, 96, 120, 144, 168, 192, 336, 504, 672, 720], 'Avg Loss': [0.5075517266748413, 0.5059373595060841, 0.5053949175823119, 0.5047441403711995, 0.49109682452774817, 0.488508376142671, 0.4892376435379828, 0.49510264829281836, 0.4896743307190557, 0.4941101271298624, 0.4937622444403748, 0.5540641330036462, 0.5489959348650539, 0.5449212579166188, 0.5413153031293083, 0.5386286418811947, 0.5371693179887884, 0.5358020797664044, 0.5263311167558035, 0.5219297783047545, 0.5222486573107102, 0.5240104695161184]}\n"
     ]
    }
   ],
   "source": [
    "loss_data = {'Prediction Length': [], 'Sequence Length': [], 'Avg Loss': []}\n",
    "\n",
    "for pred_length in [24, 720]:\n",
    "    for seq_length in [48, 72, 96, 120, 144, 168, 192, 336, 504, 672, 720]:\n",
    "        train_dataset = get_train_dataset(seq_length, pred_length)\n",
    "        test_dataset = get_test_dataset(seq_length, pred_length)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "        model = LinearLTSF(seq_length, pred_length).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        epochs = 10\n",
    "        for epoch in range(epochs):\n",
    "            train(train_dataloader, model, criterion, optimizer)\n",
    "        test_loss = test(test_dataloader, model, criterion)\n",
    "        loss_data['Avg Loss'].append(test_loss)\n",
    "        loss_data['Prediction Length'].append(pred_length)\n",
    "        loss_data['Sequence Length'].append(seq_length)\n",
    "\n",
    "print(loss_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
